---
title: "Normalization of the different studies"
author: "Mar Batlle"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
library(tidyverse)
library(readr)
library(DESeq2)
library(apeglm)
library(RobustRankAggreg)
library(BiocParallel)
register(MulticoreParam(2))
```

# GSE104766 
https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE89775

## Count matrix input
http://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html
```{r}
# Import Data
cts_GSE104766 <- read.csv("Matrices_HB/Originals_HB/GSE104766_GeneLevel_Raw_data.csv", row.names=1)
cts_GSE104766[,]<- lapply(lapply(cts_GSE104766[,-1],round),as.integer)
```

```{r}
# Import Metadata
Meta_GSE104766_path <- 'Metadata_HB/GSE104766_filtered_metadata.csv'
coldata_GSE104766 <- read.csv(Meta_GSE104766_path, row.names=1)
coldata_GSE104766$tissue[coldata_GSE104766$tissue == "Normal liver"] <- "Normal"
coldata_GSE104766$tissue <- factor(coldata_GSE104766$tissue)
```

```{r}
# delete cell line samples
cell_line_samples <- rownames(coldata_GSE104766)[coldata_GSE104766$tissue == 'Hepatoblastoma cell line']
cts_GSE104766 <- select(cts_GSE104766, -cell_line_samples)
coldata_GSE104766 <- coldata_GSE104766[!(row.names(coldata_GSE104766) %in% cell_line_samples), ]
```

```{r}
# Convert data to matrix
cts_GSE104766 <- as.matrix(cts_GSE104766)
cts_GSE104766[cts_GSE104766 < 0] <- 0
```

Check that data and metadata are consistent and in the same order
```{r}
all(rownames(coldata_GSE104766) %in% colnames(cts_GSE104766))
all(rownames(coldata_GSE104766) == colnames(cts_GSE104766))
cts_GSE104766 <- cts_GSE104766[, rownames(coldata_GSE104766)]
all(rownames(coldata_GSE104766) == colnames(cts_GSE104766))
```

## Normalization
Create DSeq2 object
```{r}
dds_GSE104766 <- DESeqDataSetFromMatrix(countData = cts_GSE104766,
                              colData = coldata_GSE104766,
                              design = ~ tissue)
```

### Pre-filtering
While it is not necessary to pre-filter low count genes before running the DESeq2 functions, there are two reasons which make pre-filtering useful: by removing rows in which there are very few reads, we reduce the memory size of the dds data object, and we increase the speed of the transformation and testing functions within DESeq2. Here we perform a minimal pre-filtering to keep only rows that have at least 10 reads total.
```{r}
keep <- rowSums(counts(dds_GSE104766)) >= 10
dds_GSE104766 <- dds_GSE104766[keep,]
```

### Factor Level
```{r}
dds_GSE104766$tissue <- relevel(dds_GSE104766$tissue, ref = "Normal")
```

### Median of ratios Normalization
https://hbctraining.github.io/DGE_workshop/lessons/02_DGE_count_normalization.html
```{r}
dds_GSE104766 <- estimateSizeFactors(dds_GSE104766)
normalized_counts_GSE104766 <- counts(dds_GSE104766, normalized=TRUE)
write.table(normalized_counts_GSE104766, file="Matrices_HB/GSE104766_normalized_counts.txt", sep="\t", quote=F, col.names=NA)
```

## Find DEGs
```{r}
dds_GSE104766 <- DESeq(dds_GSE104766, parallel=TRUE)
res_GSE104766 <- results(dds_GSE104766, parallel=TRUE)
```

```{r}
# Add Cohen's effect size
res_ES_GSE104766 <- res_GSE104766
res_ES_GSE104766$N <- nrow(coldata_GSE104766)
res_ES_GSE104766$lfcSD <- res_ES_GSE104766$lfcSE * sqrt(res_ES_GSE104766$N)
res_ES_GSE104766$ES <- res_ES_GSE104766$log2FoldChange / res_ES_GSE104766$lfcSD
```

Filter DEGs
* for p-value <0.05
* for Cohen's ES > 0.8
```{r}
res_filtered_GSE104766 <- subset(res_ES_GSE104766, padj < 0.05)
res_filtered_GSE104766  <- subset(res_filtered_GSE104766 , ES > 0.8)
nrow(res_filtered_GSE104766)
```

# GSE133039
https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE133039

## Count matrix input
```{r}
# Import Data
cts_GSE133039_path <- "Matrices_HB/Originals_HB/GSE133039_GeneLevel_Raw_data.csv"
cts_GSE133039 <- read.csv(cts_GSE133039_path, row.names=1)
cts_GSE133039[,]<- lapply(lapply(cts_GSE133039[,-1],round),as.integer)
```

```{r}
# Import Metadata
Meta_GSE133039_path <- 'Metadata_HB/GSE133039_filtered_metadata.csv'
coldata_GSE133039 <- read.csv(Meta_GSE133039_path, row.names=1)
coldata_GSE133039$tissue[coldata_GSE133039$tissue == "Tumor liver tissue"] <- "Hepatoblastoma"
coldata_GSE133039$tissue[coldata_GSE133039$tissue == "Normal liver tissue"] <- "Normal"
coldata_GSE133039$tissue <- factor(coldata_GSE133039$tissue)
```

```{r}
# Convert data to matrix
cts_GSE133039 <- as.matrix(cts_GSE133039)
```

Check that data and metadata are consistent and in the same order
```{r}
all(rownames(coldata_GSE133039) %in% colnames(cts_GSE133039))
all(rownames(coldata_GSE133039) == colnames(cts_GSE133039))
cts_GSE133039 <- cts_GSE133039[, rownames(coldata_GSE133039)]
all(rownames(coldata_GSE133039) == colnames(cts_GSE133039))
```

## Normalization
Create DSeq2 object
```{r}
dds_GSE133039 <- DESeqDataSetFromMatrix(countData = cts_GSE133039,
                              colData = coldata_GSE133039,
                              design = ~ tissue)
```

### Pre-filtering
While it is not necessary to pre-filter low count genes before running the DESeq2 functions, there are two reasons which make pre-filtering useful: by removing rows in which there are very few reads, we reduce the memory size of the dds data object, and we increase the speed of the transformation and testing functions within DESeq2. Here we perform a minimal pre-filtering to keep only rows that have at least 10 reads total.
```{r}
keep <- rowSums(counts(dds_GSE133039)) >= 10
dds_GSE133039 <- dds_GSE133039[keep,]
```

### Factor Level
```{r}
dds_GSE133039$tissue <- relevel(dds_GSE133039$tissue, ref = "Normal")
```

### Median of ratios Normalization
https://hbctraining.github.io/DGE_workshop/lessons/02_DGE_count_normalization.html
```{r}
dds_GSE133039 <- estimateSizeFactors(dds_GSE133039)
normalized_counts_GSE133039 <- counts(dds_GSE133039, normalized=TRUE)
write.table(normalized_counts_GSE133039, file="Matrices_HB/GSE133039_normalized_counts.txt", sep="\t", quote=F, col.names=NA)
```

## Find DEGs
```{r}
dds_GSE133039 <- DESeq(dds_GSE133039, parallel=TRUE)
res_GSE133039 <- results(dds_GSE133039, parallel=TRUE)
```

```{r}
# Add Cohen's effect size
res_ES_GSE133039 <- res_GSE133039
res_ES_GSE133039$N <- nrow(coldata_GSE133039)
res_ES_GSE133039$lfcSD <- res_ES_GSE133039$lfcSE * sqrt(res_ES_GSE133039$N)
res_ES_GSE133039$ES <- res_ES_GSE133039$log2FoldChange / res_ES_GSE133039$lfcSD
```

Filter DEGs
* for p-value <0.05
* for Cohen's ES > 0.8
```{r}
res_filtered_GSE133039 <- subset(res_ES_GSE133039, padj < 0.05)
res_filtered_GSE133039  <- subset(res_filtered_GSE133039 , ES > 0.8)
nrow(res_filtered_GSE133039)
```



# GSE89775
https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE133039

## Count matrix input
```{r}
# Import Data
cts_GSE89775_path <- "Matrices_HB/Originals_HB/GSE89775_GeneLevel_Raw_data.csv"
cts_GSE89775 <- read.csv(cts_GSE89775_path,sep=",", quote="", row.names=1)
cts_GSE89775[,]<- lapply(lapply(cts_GSE89775[,-1],round),as.integer)
```

```{r}
# Import Metadata
Meta_GSE89775_path <- 'Metadata_HB/GSE89775_filtered_metadata.csv'
coldata_GSE89775 <- read.csv(Meta_GSE89775_path, row.names=1)

coldata_GSE89775$tissue[coldata_GSE89775$tissue == "Hepatoblastoma liver"] <- "Hepatoblastoma"
coldata_GSE89775$tissue[coldata_GSE89775$tissue == "Normal liver"] <- "Normal"
coldata_GSE89775$tissue <- factor(coldata_GSE89775$tissue)
```


```{r}
# Convert data to matrix
cts_GSE89775 <- as.matrix(cts_GSE89775)
```

Check that data and metadata are consistent and in the same order
```{r}
all(rownames(coldata_GSE89775) %in% colnames(cts_GSE89775))
all(rownames(coldata_GSE89775) == colnames(cts_GSE89775))
cts_GSE89775<- cts_GSE89775[, rownames(coldata_GSE89775)]
all(rownames(coldata_GSE89775) == colnames(cts_GSE89775))
```

## Normalization
Create DSeq2 object
```{r}
dds_GSE89775 <- DESeqDataSetFromMatrix(countData = cts_GSE89775,
                              colData = coldata_GSE89775,
                              design = ~ tissue)
```

### Pre-filtering
While it is not necessary to pre-filter low count genes before running the DESeq2 functions, there are two reasons which make pre-filtering useful: by removing rows in which there are very few reads, we reduce the memory size of the dds data object, and we increase the speed of the transformation and testing functions within DESeq2. Here we perform a minimal pre-filtering to keep only rows that have at least 10 reads total.
```{r}
keep <- rowSums(counts(dds_GSE89775)) >= 10
dds_GSE89775 <- dds_GSE89775[keep,]
```

### Factor Level
```{r}
dds_GSE89775$tissue <- relevel(dds_GSE89775$tissue, ref = "Normal")
```

### Median of ratios Normalization
https://hbctraining.github.io/DGE_workshop/lessons/02_DGE_count_normalization.html
```{r}
dds_GSE89775 <- estimateSizeFactors(dds_GSE89775)
normalized_counts_GSE89775 <- counts(dds_GSE89775, normalized=TRUE)
write.table(normalized_counts_GSE89775, file="Matrices_HB/GSE89775_normalized_counts.txt", sep="\t", quote=F, col.names=NA)
```

## Find DEGs
```{r}
dds_GSE89775 <- DESeq(dds_GSE89775, parallel=TRUE)
res_GSE89775 <- results(dds_GSE89775, parallel=TRUE)
```

```{r}
# Add Cohen's effect size
res_ES_GSE89775 <- res_GSE89775
res_ES_GSE89775$N <- nrow(coldata_GSE89775)
res_ES_GSE89775$lfcSD <- res_ES_GSE89775$lfcSE * sqrt(res_ES_GSE89775$N)
res_ES_GSE89775$ES <- res_ES_GSE89775$log2FoldChange / res_ES_GSE89775$lfcSD
```

Filter DEGs
* for p-value <0.05
* for Cohen's ES > 0.8
```{r}
res_filtered_GSE89775 <- subset(res_ES_GSE89775, padj < 0.05)
res_filtered_GSE89775  <- subset(res_filtered_GSE89775, ES > 0.8)
nrow(res_filtered_GSE89775)
```

# GSE151347
https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE133039

## Count matrix input
```{r}
# Import Data
cts_GSE151347_path <- "Matrices_HB/Originals_HB/GSE151347_GeneLevel_Raw_data.csv"
cts_GSE151347 <- read.csv(cts_GSE151347_path,sep=",", quote="", row.names=1)
cts_GSE151347[,]<- lapply(lapply(cts_GSE151347[,-1],round),as.integer)
```

```{r}
# Import Metadata
Meta_GSE151347_path <- 'Metadata_HB/GSE151347_filtered_metadata.csv'
coldata_GSE151347 <- read.csv(Meta_GSE151347_path, row.names=1)
names(coldata_GSE151347)[names(coldata_GSE151347) == "tissue.type"] <- "tissue"
coldata_GSE151347$tissue[coldata_GSE151347$tissue == "Normal liver"] <- "Normal"
coldata_GSE151347$tissue <- factor(coldata_GSE151347$tissue)
```

```{r}
# Convert data to matrix
cts_GSE89775 <- as.matrix(cts_GSE151347)
```

Check that data and metadata are consistent and in the same order
```{r}
all(rownames(coldata_GSE151347) %in% colnames(cts_GSE151347))
all(rownames(coldata_GSE151347) == colnames(cts_GSE151347))
cts_GSE151347 <- cts_GSE151347[, rownames(coldata_GSE151347)]
all(rownames(coldata_GSE151347) == colnames(cts_GSE151347))
```
## Normalization
Create DSeq2 object
```{r}
dds_GSE151347 <- DESeqDataSetFromMatrix(countData = cts_GSE151347,
                              colData = coldata_GSE151347,
                              design = ~ tissue)
```

### Pre-filtering
While it is not necessary to pre-filter low count genes before running the DESeq2 functions, there are two reasons which make pre-filtering useful: by removing rows in which there are very few reads, we reduce the memory size of the dds data object, and we increase the speed of the transformation and testing functions within DESeq2. Here we perform a minimal pre-filtering to keep only rows that have at least 10 reads total.
```{r}
keep <- rowSums(counts(dds_GSE151347)) >= 10
dds_GSE151347 <- dds_GSE151347[keep,]
```

### Factor Level
```{r}
dds_GSE151347$tissue <- relevel(dds_GSE151347$tissue, ref = "Normal")
```

### Median of ratios Normalization
https://hbctraining.github.io/DGE_workshop/lessons/02_DGE_count_normalization.html
```{r}
dds_GSE151347 <- estimateSizeFactors(dds_GSE151347)
normalized_counts_GSE151347 <- counts(dds_GSE151347, normalized=TRUE)
write.table(normalized_counts_GSE151347, file="Matrices_HB/GSE151347_normalized_counts.txt", sep="\t", quote=F, col.names=NA)
```

## Find DEGs
```{r}
dds_GSE151347 <- DESeq(dds_GSE151347)
res_GSE151347 <- results(dds_GSE151347)
```

```{r}
# Add Cohen's effect size
res_ES_GSE151347 <- res_GSE151347
res_ES_GSE151347$N <- nrow(coldata_GSE151347)
res_ES_GSE151347$lfcSD <- res_ES_GSE151347$lfcSE * sqrt(res_ES_GSE151347$N)
res_ES_GSE151347$ES <- res_ES_GSE151347$log2FoldChange / res_ES_GSE151347$lfcSD
```

Filter DEGs
* for p-value <0.05
* for Cohen's ES > 0.8
```{r}
res_filtered_GSE151347 <- subset(res_ES_GSE151347, padj < 0.05)
res_filtered_GSE151347  <- subset(res_filtered_GSE151347, ES > 0.8)
nrow(res_filtered_GSE151347)
```

# Rank Effecct Score
## Join data
```{r}
ES_GSE89775 <- as.matrix(subset(res_filtered_GSE89775, select = c(ES)))
colnames(ES_GSE89775)[colnames(ES_GSE89775) == "ES"] <- "ES_GSE89775"
ES_GSE89775 <- cbind(genes = rownames(ES_GSE89775), ES_GSE89775)

ES_GSE104766 <- as.matrix(subset(res_filtered_GSE104766, select = c(ES)))
colnames(ES_GSE104766)[colnames(ES_GSE104766) == "ES"] <- "ES_GSE104766"
ES_GSE104766 <- cbind(genes = rownames(ES_GSE104766), ES_GSE104766)

ES_GSE133039 <- as.matrix(subset(res_filtered_GSE133039, select = c(ES)))
colnames(ES_GSE133039)[colnames(ES_GSE133039) == "ES"] <- "ES_GSE133039"
ES_GSE133039 <- cbind(genes = rownames(ES_GSE133039), ES_GSE133039)

ES_GSE151347 <- as.matrix(subset(res_filtered_GSE151347, select = c(ES)))
colnames(ES_GSE151347)[colnames(ES_GSE151347) == "ES"] <- "ES_GSE151347"
ES_GSE151347 <- cbind(genes = rownames(ES_GSE151347), ES_GSE151347)

ES_joint <-merge(x = ES_GSE89775, y = ES_GSE104766, by= 'genes' , all = TRUE)
ES_joint <-merge(x = ES_joint, y = ES_GSE133039, by= 'genes' , all = TRUE)
ES_joint <-merge(x = ES_joint, y = ES_GSE151347, by= 'genes' , all = TRUE)

ES_joint$ES_GSE89775 <- as.double(ES_joint$ES_GSE89775)
ES_joint$ES_GSE104766 <- as.double(ES_joint$ES_GSE104766)
ES_joint$ES_GSE133039 <- as.double(ES_joint$ES_GSE133039)
ES_joint$ES_GSE151347 <- as.double(ES_joint$ES_GSE151347)

ES_joint
```
```{r}
library('biomaRt')
mart <- useDataset("hsapiens_gene_ensembl", useMart("ensembl"))
genes <- ES_joint$genes
G_list <- getBM(filters= "ensembl_gene_id", attributes= c("ensembl_gene_id","hgnc_symbol"),values=genes,mart= mart)

```

```{r}
ES_joint.2<-ES_joint
ES_joint.2 <- merge(ES_joint.2,G_list,by.x="genes",by.y="ensembl_gene_id")
ES_joint.2 <- subset(ES_joint.2, select = -genes)
ES_joint.2 <- aggregate(ES_joint.2[,1:4], list(ES_joint.2$hgnc_symbol), mean)
ES_joint.2 <- ES_joint.2[-which(ES_joint.2$Group.1 == ""), ]
row.names(ES_joint.2) <- ES_joint.2$Group.1
ES_joint.2 <- subset(ES_joint.2, select = -Group.1)
```


# Create ranks

```{r}
r = rankMatrix(ES_joint, full = TRUE)
```

```{r}



aggregateRanks(ES_joint, n_valid_srcs=4, min_src=2, method='geom')
```


```{r}
data = data.frame(GeneID=c("15364", "56520", "57781", "58180", "18035"),
                source1scores=c(0.9,0.5,0.3,NA,NA),
                source2scores=c(0.7,NA,0.8,0.6,0.5),
                source3scores=c(0.5,NA,0.3,0.1,0.2))
data #dataframe with scores
aggregateRanks(ES_joint, n_valid_srcs=3, min_src=2, method='geom')
#note how gene 56520 is eliminated as it appeared in fewer than 2 sources
```



```{r}

```


```{r}
r = rankMatrix(ES_joint)
```

```


